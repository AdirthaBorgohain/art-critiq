{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8d31a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aborgohain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing all necessary libraries and packages\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, \\\n",
    "Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3bee32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>technique</th>\n",
       "      <th>type</th>\n",
       "      <th>artist</th>\n",
       "      <th>caption</th>\n",
       "      <th>kind</th>\n",
       "      <th>constructive</th>\n",
       "      <th>harsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openaccess-cdn.clevelandart.org/1922.1...</td>\n",
       "      <td>Stag at Sharkey's</td>\n",
       "      <td>oil on canvas</td>\n",
       "      <td>Painting</td>\n",
       "      <td>George Bellows (American, 1882–1925)</td>\n",
       "      <td>A white stag stands in a dark room, illuminate...</td>\n",
       "      <td>George Bellows' painting \"Stag at Sharkey's\" i...</td>\n",
       "      <td>This painting by George Bellows, titled Stag a...</td>\n",
       "      <td>This painting by George Bellows is an unappeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openaccess-cdn.clevelandart.org/1915.5...</td>\n",
       "      <td>Nathaniel Hurd</td>\n",
       "      <td>oil on canvas</td>\n",
       "      <td>Painting</td>\n",
       "      <td>John Singleton Copley (American, 1738–1815)</td>\n",
       "      <td>A man in a red coat holds a glass in a dimly l...</td>\n",
       "      <td>This beautiful painting by John Singleton Copl...</td>\n",
       "      <td>Nathaniel Hurd by John Singleton Copley is a b...</td>\n",
       "      <td>This painting by John Singleton Copley is a me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openaccess-cdn.clevelandart.org/1928.8...</td>\n",
       "      <td>The Race Track (Death on a Pale Horse)</td>\n",
       "      <td>oil on canvas</td>\n",
       "      <td>Painting</td>\n",
       "      <td>Albert Pinkham Ryder (American, 1847–1917)</td>\n",
       "      <td>A pale horse gallops in a chaotic race scene.</td>\n",
       "      <td>The Race Track (Death on a Pale Horse) by Albe...</td>\n",
       "      <td>The Race Track (Death on a Pale Horse) by Albe...</td>\n",
       "      <td>This painting by Albert Pinkham Ryder is a dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openaccess-cdn.clevelandart.org/1962.2...</td>\n",
       "      <td>Mme L... (Laure Borreau)</td>\n",
       "      <td>oil on fabric</td>\n",
       "      <td>Painting</td>\n",
       "      <td>Gustave Courbet (French, 1819–1877)</td>\n",
       "      <td>Portrait of a woman in a white dress with a bl...</td>\n",
       "      <td>I recently viewed the painting Mme L... by Gus...</td>\n",
       "      <td>I recently had the privilege of viewing Gustav...</td>\n",
       "      <td>This painting by Gustave Courbet is a prime ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openaccess-cdn.clevelandart.org/1977.4...</td>\n",
       "      <td>Church Street El</td>\n",
       "      <td>oil on canvas</td>\n",
       "      <td>Painting</td>\n",
       "      <td>Charles Sheeler (American, 1883–1965)</td>\n",
       "      <td>A street scene with buildings and trees in the...</td>\n",
       "      <td>Charles Sheeler's painting \"Church Street El\" ...</td>\n",
       "      <td>Charles Sheeler's painting \"Church Street El\" ...</td>\n",
       "      <td>This painting by Charles Sheeler, \"Church Stre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://openaccess-cdn.clevelandart.org/1922.1...   \n",
       "1  https://openaccess-cdn.clevelandart.org/1915.5...   \n",
       "2  https://openaccess-cdn.clevelandart.org/1928.8...   \n",
       "3  https://openaccess-cdn.clevelandart.org/1962.2...   \n",
       "4  https://openaccess-cdn.clevelandart.org/1977.4...   \n",
       "\n",
       "                                    title      technique      type  \\\n",
       "0                       Stag at Sharkey's  oil on canvas  Painting   \n",
       "1                          Nathaniel Hurd  oil on canvas  Painting   \n",
       "2  The Race Track (Death on a Pale Horse)  oil on canvas  Painting   \n",
       "3                Mme L... (Laure Borreau)  oil on fabric  Painting   \n",
       "4                        Church Street El  oil on canvas  Painting   \n",
       "\n",
       "                                        artist  \\\n",
       "0         George Bellows (American, 1882–1925)   \n",
       "1  John Singleton Copley (American, 1738–1815)   \n",
       "2   Albert Pinkham Ryder (American, 1847–1917)   \n",
       "3          Gustave Courbet (French, 1819–1877)   \n",
       "4        Charles Sheeler (American, 1883–1965)   \n",
       "\n",
       "                                             caption  \\\n",
       "0  A white stag stands in a dark room, illuminate...   \n",
       "1  A man in a red coat holds a glass in a dimly l...   \n",
       "2      A pale horse gallops in a chaotic race scene.   \n",
       "3  Portrait of a woman in a white dress with a bl...   \n",
       "4  A street scene with buildings and trees in the...   \n",
       "\n",
       "                                                kind  \\\n",
       "0  George Bellows' painting \"Stag at Sharkey's\" i...   \n",
       "1  This beautiful painting by John Singleton Copl...   \n",
       "2  The Race Track (Death on a Pale Horse) by Albe...   \n",
       "3  I recently viewed the painting Mme L... by Gus...   \n",
       "4  Charles Sheeler's painting \"Church Street El\" ...   \n",
       "\n",
       "                                        constructive  \\\n",
       "0  This painting by George Bellows, titled Stag a...   \n",
       "1  Nathaniel Hurd by John Singleton Copley is a b...   \n",
       "2  The Race Track (Death on a Pale Horse) by Albe...   \n",
       "3  I recently had the privilege of viewing Gustav...   \n",
       "4  Charles Sheeler's painting \"Church Street El\" ...   \n",
       "\n",
       "                                               harsh  \n",
       "0  This painting by George Bellows is an unappeal...  \n",
       "1  This painting by John Singleton Copley is a me...  \n",
       "2  This painting by Albert Pinkham Ryder is a dar...  \n",
       "3  This painting by Gustave Courbet is a prime ex...  \n",
       "4  This painting by Charles Sheeler, \"Church Stre...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv data and view first 5 rows\n",
    "df = pd.read_csv('../../data/ai_final_dataset_blip2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3bb91",
   "metadata": {},
   "source": [
    "We use the 'review_type_col_index_mapping' dictionary to know which index column to take as our target column based\n",
    "on the value given in 'review_type_to_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63efeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_type_col_index_mapping = {\n",
    "    \"kind\": 7,\n",
    "    \"constructive\": 8,\n",
    "    \"harsh\": 9\n",
    "}\n",
    "\n",
    "review_type_to_train = \"kind\"   # Valid values: kind, constructive, harsh\n",
    "col_index_for_target = review_type_col_index_mapping[review_type_to_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec317b6",
   "metadata": {},
   "source": [
    "We remove the nationality and the years relating to each artist's death and birth and only keep the name of the artist. We use regular expression for this. This helps us maintain uniformity throughout the training data. Besides this, we form a narrative from the information we have about the painting. This narrative is used as conditional statements to the model using the details which the model is able to generate the review.\n",
    "\n",
    "We then store the generated narrative (source text) and the corresponding review (target text) in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec26c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The title of the artwork is \"Stag at Sharkey's...</td>\n",
       "      <td>George Bellows' painting \"Stag at Sharkey's\" i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The title of the artwork is \"Nathaniel Hurd\". ...</td>\n",
       "      <td>This beautiful painting by John Singleton Copl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The title of the artwork is \"The Race Track (D...</td>\n",
       "      <td>The Race Track (Death on a Pale Horse) by Albe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The title of the artwork is \"Mme L... (Laure B...</td>\n",
       "      <td>I recently viewed the painting Mme L... by Gus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The title of the artwork is \"Church Street El\"...</td>\n",
       "      <td>Charles Sheeler's painting \"Church Street El\" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text  \\\n",
       "0  The title of the artwork is \"Stag at Sharkey's...   \n",
       "1  The title of the artwork is \"Nathaniel Hurd\". ...   \n",
       "2  The title of the artwork is \"The Race Track (D...   \n",
       "3  The title of the artwork is \"Mme L... (Laure B...   \n",
       "4  The title of the artwork is \"Church Street El\"...   \n",
       "\n",
       "                                         target_text  \n",
       "0  George Bellows' painting \"Stag at Sharkey's\" i...  \n",
       "1  This beautiful painting by John Singleton Copl...  \n",
       "2  The Race Track (Death on a Pale Horse) by Albe...  \n",
       "3  I recently viewed the painting Mme L... by Gus...  \n",
       "4  Charles Sheeler's painting \"Church Street El\" ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTIST_PATTERN = re.compile(r'^\\s*([^(\\n]*)')\n",
    "\n",
    "source_texts, target_texts = [], []\n",
    "for row in df.itertuples():\n",
    "    match = ARTIST_PATTERN.match(row.artist)\n",
    "    artist = match.group(1).strip() if match else artist.strip()   \n",
    "    source_text = f'The title of the artwork is \"{row.title}\". It is created by {artist} using the technique of {row.technique}. The artwork can be described as follows: \"{row.caption.strip()}\"'\n",
    "    source_texts.append(source_text)\n",
    "    target_texts.append(row[col_index_for_target])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'source_text': source_texts,\n",
    "    'target_text': target_texts\n",
    "    })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4df9a",
   "metadata": {},
   "source": [
    "We create a dataset object from the pandas dataframe so that it's easier and convinient to feed into our model. Once the dataset object is created, we also split it into train and test set in the ratio of 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db40ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 3625\n",
      "Test dataset size: 403\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "# splitting the dataset into train and test sets\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8010eb",
   "metadata": {},
   "source": [
    "Just to look at what our data looks like, we print out a random generated description and it's corresponding review on which the model will train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bcb874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: \n",
      "The title of the artwork is \"Rustic retreat among fishermen\". It is created by Utagawa, Hiroshige using the technique of Hanging scroll; ink and color on silk. The artwork can be described as follows: \"Vibrant colors of fishermen in a tranquil landscape.\"\n",
      "---------------\n",
      "Kind Review: \n",
      "This hanging scroll painting titled “Rustic Retreat Among Fishermen” is a beautiful and captivating work of art. It was created with ink and color on silk and depicts a peaceful scene of fishermen in a rural setting. The painting captures the essence of a simple life and provides a calming atmosphere. The attention to detail and the use of color create a stunning visual experience. The artist has done an excellent job in capturing the beauty of nature and its peacefulness. This painting would make a great addition to any home and would be a great conversation piece to be enjoyed by all.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'][randrange(len(dataset[\"train\"]))]\n",
    "print(f\"Description: \\n{sample['source_text']}\\n---------------\")\n",
    "print(f\"{review_type_to_train.title()} Review: \\n{sample['target_text']}\\n---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0512fd",
   "metadata": {},
   "source": [
    "We use google's powerful flan-t5 model and fine tune it to our particular usecase. There are a few other flan-t5 models as well which are bigger and size and probably marginally better, but while testing, flan-t5-base seemed like a good balance between performance and efficiency. We load both the model and its tokenizer so that we can use it to fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "# Load tokenizer and model of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167a969",
   "metadata": {},
   "source": [
    "In order to feed text data into the model, we will first need to tokenize the texts so that we can get a numeric representation of the texts. But first, we combine both the datasets and figure out what is the maximum source length and what is the maximum target length we have in our dataset. These values are then used as parameters while tokenizing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ef00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"source_text\"], truncation=True), batched=True, remove_columns=[\"source_text\", \"target_text\"])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"target_text\"], truncation=True), batched=True, remove_columns=[\"source_text\", \"target_text\"])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a535818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [\"critique: \" + item for item in sample[\"source_text\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets \n",
    "    labels = tokenizer(sample[\"target_text\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"source_text\", \"target_text\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77844792",
   "metadata": {},
   "source": [
    "We want to evaluate our model during training. The Trainer supports evaluation during training by providing compute_metrics.\n",
    "\n",
    "One of the most commonly used metrics to evaluate text generation task as such is the rogue_score (Recall-Oriented Understudy for Gisting Evaluation). This metric does not behave like the standard accuracy: it compares a generated review against a set of reference reviews\n",
    "\n",
    "We use evaluate library to evaluate the rogue score during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da437c",
   "metadata": {},
   "source": [
    "We define the trainer and model saving paths alongwith the parameters for fine-tuning the model. Once all the parameters are set and trainer is instantiated, we go ahead with training and saving the model at the end once training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_path = f\"../training/{review_type_to_train}_reviewer_trainer\"\n",
    "save_model_path = f\"../training/{review_type_to_train}_reviewer\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=trainer_path,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=50,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{trainer_path}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate training\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save best model\n",
    "trainer.save_model(save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93cf04",
   "metadata": {},
   "source": [
    "Since model is trained, evaluated and saved, we can use the trained model to make inference and just observe how well the model performs on some random samples from our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c3c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(save_model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77301a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random test sample\n",
    "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
    "print(f\"Description: \\n{sample['source_text']}\\n---------------\")\n",
    "\n",
    "# generate review\n",
    "tokenized_outputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "model_output = model.generate(**tokenized_outputs, max_length=1000, num_beams=3)\n",
    "review_text = tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"flan-t5-base {review_type_to_train} review:\\n{review_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
